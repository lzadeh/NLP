{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring techniques for NLP\n",
    "As we mentioned in the lecture slides, the different approaches used to solve NLP problems commonly fall into three categories: \n",
    "- rule-based, \n",
    "- machine learning, and \n",
    "- deep learning. \n",
    "\n",
    "In this notebook we will try to show you how to use different approaches to solve NLP problems. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based technique\n",
    "Similar to other early AI systems, early attempts at designing NLP systems were based on building rules for the task at hand. This required that the developers had some expertise in the domain to formulate rules that could be incorporated into a program. Such systems also required resources like dictionaries and thesauruses, typically compiled and digitized over a period of time.\n",
    "\n",
    "Regular expressions (regex) are a great tool for text analysis and building rule-based systems. A regex is a set of characters or a pattern that is used to match and find substrings in text. For example, a regex like <b><font color='maroon'>‘^([a-zA-Z0-9_\\-\\.]+)@([a-zA-Z0-9_\\-\\.] +)\\.([a-zA-Z]{2,5})$’</font></b> is used to find all email IDs in a piece of text. Regexes are a great way to incorporate domain knowledge in your NLP system. For example, given a job advertisement, we want to build a system to automatically identify the contract type, the job title, and the salary. There are a variety of contract types and salary ranges available. These can be easily matched with regexes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scenario: Consider a recruiting agent that tries to match candidates with available opportunities by identifying contract type, job title, and salary range from the following list of job descriptions:\n",
    "\n",
    "- <b>Job Description 1:</b> \"We are looking for a full-time software engineer to join our team. The salary for this position is $100,000 per year.\"\n",
    "- <b>Job Description 2:</b> \"Our company is offering a part-time administrative assistant job with a salary range of $20-25 per hour.\" \n",
    "- <b>Job Description 3:</b> \"This is a 6-month internship opportunity for a data analyst. The contract rate is $75,000 per year.\" \n",
    "\n",
    "Regular expression can be used to find all the match for contact types, job titles and salary ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('full-time', 'Software engineer', '$100,000')\n",
      "('part-time', 'Administrative assistant', '$20-25')\n",
      "('internship', 'Data analyst', '$75,000')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_information(text):\n",
    "  contract_pattern = r'(full-time|part-time|contract|internship)'\n",
    "  title_pattern = r'^Title: ([a-zA-Z]+ [a-zA-Z]+){1}'\n",
    "  salary_pattern = r'\\$(\\d+(,|-)+\\d+)'\n",
    "  \n",
    "  contract = re.search(contract_pattern, text, re.IGNORECASE)\n",
    "  title = re.search(title_pattern, text, re.IGNORECASE)\n",
    "  salary = re.search(salary_pattern, text, re.IGNORECASE)\n",
    "  \n",
    "  if contract:\n",
    "    contract = contract.group(1)\n",
    "  if title:\n",
    "    title = title.group(1)\n",
    "  if salary:\n",
    "    salary = salary.group(0)\n",
    "  \n",
    "  return contract, title, salary\n",
    "\n",
    "text1 = \"Title: Software engineer, Description: We are looking for a full-time software engineer to join our team. The salary for this position is $100,000 per year.\"\n",
    "text2 = \"Title: Administrative assistant, Description: Our company is offering a part-time administrative assistant job with a salary range of $20-25 per hour.\"\n",
    "text3 = \"Title: Data analyst, Description: This is a 6-month internship opportunity for a data analyst. The contract rate is $75,000 per year.\"\n",
    "\n",
    "print(extract_information(text1))\n",
    "print(extract_information(text2))\n",
    "print(extract_information(text3))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regular expressions used in this code are designed to capture common patterns in job post data, but they may not capture all possible variations. The code can be further refined and improved to capture more specific cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information retrival\n",
    "One major challenge in NLP is creating structured data from unstructured and/or semi-structured documents. Information extraction is one of the NLP tasks to retrieve structured data from normal text. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "The following texts have been selected from a newspaper about the best players of the Champion League in 2022:\n",
    "\n",
    "- Karim Mostafa Benzema is a French professional footballer who plays as a striker for La Liga club Real Madrid and the France national team.\n",
    "- Kylian Mbappé Lottin is a French professional footballer who plays as a forward for Ligue 1 club Paris Saint-Germain and the France national team \n",
    "- Lewandowski is a Polish professional footballer who plays as a striker for Bundesliga club Bayern Munich and is the captain of the Poland national team. \n",
    "\n",
    "Let's create a function and pass a pattern and text to return the first match of the pattern inside the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_match_text(pattern, text):\n",
    "    match_items = re.findall(pattern, text)\n",
    "    if match_items:\n",
    "        return match_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "player1 = 'Karim Mostafa Benzema is a French professional footballer who plays as a striker for La Liga club Real Madrid and the France national team.'\n",
    "player2 = 'Kylian Mbappé Lottin is a French professional footballer who plays as a forward for Ligue 1 club Paris Saint-Germain and the France national team'\n",
    "player3 = 'Lewandowski is a Polish professional footballer who plays as a striker for Bundesliga club Bayern Munich and is the captain of the Poland national team.'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Exercise 1 </font>\n",
    "Write a pattern to extract name of first player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Karim Mostafa Benzema '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a pattern to extract name of the player1\n",
    "pattern = '([A-Z]+[a-zA-Z]* [A-Z]+[a-zA-Z]* [A-Z]+[a-zA-Z]* )'\n",
    "#pattern = '?'\n",
    "get_match_text(pattern ,player1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'> Exercise 2 </font>\n",
    "Write a pattern to extract the club name for the second player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paris Saint-Germain'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a pattern to extract the club name for the second player.\n",
    "pattern = 'club ([A-Z]+[a-zA-Z]* [A-Z]+[a-zA-Z-]*)'\n",
    "# pattern = '?'\n",
    "get_match_text(pattern ,player2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Exercise 3 </font>\n",
    "Write a pattern to retrive the national team name for third player."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Poland '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a pattern to retrive the national team name for third player.\n",
    "pattern = '([A-Z]+[a-zA-Z]* )national team'\n",
    "# pattern = '?'\n",
    "get_match_text(pattern ,player3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning for NLP\n",
    "In the following sections you can see some interesting examples of deep learning techniques for NLP.\n",
    "- Sample 1: Sentiment analysis\n",
    "- Sample 2: Text generation \n",
    "- Sample 3: Question answering\n",
    "\n",
    "Transformer is one of the advance deep learning techniques for executing various NLP tasks. We will cover them in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to install tensorflow and transformers packages\n",
    "# !pip install tensorflow\n",
    "# !pip install -q transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import transformers pipeline\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some layers from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing TFDistilBertForSequenceClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9997692704200745},\n",
       " {'label': 'NEGATIVE', 'score': 0.9990854263305664}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a ready to use sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "data = [\"I love NLP\", \"I hate NLP\"]\n",
    "sentiment_pipeline(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Natural language processing (NLP) is not as easily implemented or as expensive as some linguists think. One possible alternative might be to focus on the'},\n",
       " {'generated_text': 'Natural language processing (NLP) is not an easy task for a computer science student to understand. But, after studying the work on how NLP'},\n",
       " {'generated_text': 'Natural language processing (NLP) is a fairly recent breakthrough in neural network research. As mentioned previously, NLP can recognize words in three different ways'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating text using a text generation pipeline\n",
    "text_generator = pipeline(\"text-generation\", model = 'gpt2') \n",
    "text_generator(\"Natural language processing (NLP) is\", max_length = 30, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some layers from the model checkpoint at distilbert-base-cased-distilled-squad were not used when initializing TFDistilBertForQuestionAnswering: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-cased-distilled-squad and are newly initialized: ['dropout_301']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.9869260191917419,\n",
       " 'start': 1,\n",
       " 'end': 28,\n",
       " 'answer': 'Natural language processing'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answering questions using a question answering pipeline\n",
    "nlp = pipeline(\"question-answering\") \n",
    "context = \"\"\" Natural language processing (NLP) is a subfield of linguistics, computer science, \n",
    "                and artificial intelligence concerned with the interactions between computers \n",
    "                and human language, in particular how to program computers to process and analyze \n",
    "                large amounts of natural language data. \n",
    "                The result is a computer capable of \"understanding\" the contents of documents, \n",
    "                including the contextual nuances of the language within them. The technology can \n",
    "                then accurately extract information and insights contained in the documents \n",
    "                as well as categorize and organize the documents themselves. \"\"\" \n",
    "nlp(question=\"What is NLP?\", context=context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "778111f43dd4467f233eb510082683772f85150aae7e84a1db9ec8d6d394ff07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
