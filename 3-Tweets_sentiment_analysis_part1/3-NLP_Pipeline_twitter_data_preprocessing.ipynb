{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring NLP Pipeline (Part 1)\n",
    "As we mentioned in the lecture slides, an NLP pipeline is constructed from  the following steps: \n",
    "- Data acquisition, \n",
    "- Text extraction and cleaning \n",
    "- Pre-processing\n",
    "- Feature Engineering\n",
    "- Modelling\n",
    "- Evaluation\n",
    "- Deployement\n",
    "- Monitoring & Model updating\n",
    "\n",
    "In this notebook we will try to explain some of these steps using Pandas,NLTK, String, Contractions and Scikit-learn libraries.  You can open the cloud version of this notebook using the following link:\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/Ali-Alameer/NLP/blob/main/week2_code.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweets Sentiment Analysis\n",
    "With all of the tweets circulating every second, it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in the language is important in these times where decisions and reactions are created and updated in seconds. In this workshop, we'll create an NLP pipeline to predict the sentiment of each tweet.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition\n",
    "\n",
    "In order to do any type of NLP analysis one requires data to analyze. The twitter data can be collected using the twitter API (https://developer.twitter.com/en/docs/twitter-api). Twitter API is the official programmatic endpoint provided by Twitter. It allows developers to access the enormous amount of public data on Twitter that millions of users share daily. \n",
    "\n",
    "Tweepy (https://www.tweepy.org/) is an easy-to-use Python library for accessing the Twitter API. Its API class provides access to the RESTful methods of the Twitter API. We will skip the data acquisition process for this workshop in order to keep it short. However, you can develop the process of extracting tweets from Twitter API as an individual project for your portfolio."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "\n",
    "The second step in the NLP pipeline is extracting the text from its native form (such as pdf, image or html files). \n",
    "\n",
    "Our dataset is a CSV(Comma Separated Values) file that contains tweets data. Each row contains the text of a tweet and a sentiment label. We will use the <b>Pandas</b> library to read the CSV file and load data into a dataframe.\n",
    "\n",
    "A <b>Pandas DataFrame</b> is a 2 dimensional data structure, like a 2 dimensional array, or a table with rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_raw = pd.read_csv('./data/train_tweets.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let to check the loaded data by displaying the first 5 tweets in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>[2/2] huge fan fare and big talking before the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>@user camping tomorrow @user @user @user @use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>the next school year is the year for exams.ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>we won!!! love the land!!! #allin #cavs #champ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user welcome here !  i'm   it's so #gr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation\n",
       "5   6      0  [2/2] huge fan fare and big talking before the...\n",
       "6   7      0   @user camping tomorrow @user @user @user @use...\n",
       "7   8      0  the next school year is the year for exams.ð...\n",
       "8   9      0  we won!!! love the land!!! #allin #cavs #champ...\n",
       "9  10      0   @user @user welcome here !  i'm   it's so #gr..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of training data\n",
    "train_raw.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find out how the data is structured, let's take a look at it. There will be a result showing how many rows and columns the dataset contains by printing the shape attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The id column is not required in our process so we can remove this column. Also, we can rearrange columns in the dataset by brining the tweet text in the first column and a sentiment label in the second column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment\n",
       "0   @user when a father is dysfunctional and is s...          0\n",
       "1  @user @user thanks for #lyft credit i can't us...          0\n",
       "2                                bihday your majesty          0\n",
       "3  #model   i love u take with u all the time in ...          0\n",
       "4             factsguide: society now    #motivation          0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rearrange the columns in the training dataset\n",
    "# and remove the id column\n",
    "train_df = train_raw[['tweet', 'label']]\n",
    "train_df.columns = ['tweet', 'sentiment']\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the number of positive and negative tweets using the value_counts() method of a dataframe object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29720\n",
       "1     2242\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sentiment.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset description indicates that:\n",
    "- <b>0</b> ==> <b>positive sentiments</b>\n",
    "- <b>1</b> ==> <b>negative sentiments</b>\n",
    "\n",
    "According to the result of the previous cell, there are 29,720 positive tweets and 2,242 negative tweets in the training dataset. As a result, the training dataset is <b>imbalanced</b> since the data points are not equal for the two classes.\n",
    "\n",
    "For storing sentiments, a Python dictionary is an appropriate data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dictionary to map numbers to corresponding sentiments\n",
    "map = {0: 'positive', 1: 'negative'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text cleaning & pre-processing\n",
    "\n",
    "Why Do We Need to clean and pre-process Text?\n",
    "\n",
    "- <b>Extracting plain text</b>: Textual data can come from a wide variety of sources: the web, PDFs, word documents, speech recognition systems, book scans, etc. Your goal is to extract plain text that is free of any source specific markup or constructs that are not relevant to your task.\n",
    "- <b>Reducing complexity</b>: Some features of our language like capitalization, punctuation, and common words such as a, of, and the, often help provide structure, but don't add much meaning. Sometimes it's best to remove them if that helps reduce the complexity of the procedures you want to apply later.\n",
    "\n",
    "\n",
    "In order to clean the text of tweets, we will first create a function that lowercase text, expand contractions, removes text enclosed in square brackets, removes links, removes punctuation, and removes words containing numbers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "import contractions\n",
    "\n",
    "def clean_text(text):\n",
    "    # make text lowercase\n",
    "    text = str(text).lower()\n",
    "    # expand contractions\n",
    "    text = \" \".join([contractions.fix(token) for token in str(text).split()])\n",
    "    # remove text enclosed in square brackets\n",
    "    text = re.sub(r\"\\[.*?\\]\", \"\", text)\n",
    "    # remove text in angle brackets\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "    # remove links\n",
    "    text = re.sub(\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "    # remove punctuation\n",
    "    text = re.sub('[%s]' % re.escape(punctuation), \"\", text)\n",
    "    # remove words containing numbers\n",
    "    text = re.sub('\\w*\\d\\w*', \"\", text)\n",
    "    # remove new lines\n",
    "    text = re.sub(\"\\n\", \"\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "      <td>user when a father is dysfunctional and is so ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks for lyft credit i cannot use ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment  \\\n",
       "0   @user when a father is dysfunctional and is s...          0   \n",
       "1  @user @user thanks for #lyft credit i can't us...          0   \n",
       "2                                bihday your majesty          0   \n",
       "3  #model   i love u take with u all the time in ...          0   \n",
       "4             factsguide: society now    #motivation          0   \n",
       "\n",
       "                                         clean_tweet  \n",
       "0  user when a father is dysfunctional and is so ...  \n",
       "1  user user thanks for lyft credit i cannot use ...  \n",
       "2                                bihday your majesty  \n",
       "3  model i love you take with you all the time in...  \n",
       "4                  factsguide society now motivation  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply clean text fuction on each twitte in the training dataset\n",
    "train_df['clean_tweet'] = train_df['tweet'].apply(lambda x: clean_text(x))\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Exercise</font>\n",
    "\n",
    "Complete the following code to create a column named \"no_sentences\" containing the number of sentences for each tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\SES100\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# calculate the number of sentences for each tweet\n",
    "train_raw['no_sentences']  = ?\n",
    "\n",
    "train_raw.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tokenization\n",
    "\n",
    "Now we can tokenize tweets into words and extract a list of words for each tweet. We can use the NLTK word tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>word_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "      <td>user when a father is dysfunctional and is so ...</td>\n",
       "      <td>[user, when, a, father, is, dysfunctional, and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks for lyft credit i cannot use ...</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, i, can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>[model, i, love, you, take, with, you, all, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment  \\\n",
       "0   @user when a father is dysfunctional and is s...          0   \n",
       "1  @user @user thanks for #lyft credit i can't us...          0   \n",
       "2                                bihday your majesty          0   \n",
       "3  #model   i love u take with u all the time in ...          0   \n",
       "4             factsguide: society now    #motivation          0   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  user when a father is dysfunctional and is so ...   \n",
       "1  user user thanks for lyft credit i cannot use ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                           word_list  \n",
       "0  [user, when, a, father, is, dysfunctional, and...  \n",
       "1  [user, user, thanks, for, lyft, credit, i, can...  \n",
       "2                            [bihday, your, majesty]  \n",
       "3  [model, i, love, you, take, with, you, all, th...  \n",
       "4             [factsguide, society, now, motivation]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "train_df['word_list'] = train_df['clean_tweet'].apply(lambda x: word_tokenize(x))\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the most common words in tweets text\n",
    "\n",
    "Before removing stop words it is worth looking at the tweet's word list and extracting the most common words in tweet texts. This step will help us to understand why we need to remove stop words from the word list. \n",
    "\n",
    "In the \"collections\" module of python, you'll find a class specially designed to count several different objects in one go. This class is conveniently called <b>Counter</b>. We use the Counter class to count the number of repetitions of a word in the word list column and then we store the result in a new dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_71357_row0_col1 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_71357_row1_col1 {\n",
       "  background-color: #66abd4;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_71357_row2_col1 {\n",
       "  background-color: #68acd5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_71357_row3_col1 {\n",
       "  background-color: #aacfe5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row4_col1 {\n",
       "  background-color: #afd1e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row5_col1 {\n",
       "  background-color: #c2d9ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row6_col1 {\n",
       "  background-color: #c7dcef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row7_col1 {\n",
       "  background-color: #d7e6f5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row8_col1 {\n",
       "  background-color: #dae8f6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row9_col1 {\n",
       "  background-color: #dceaf6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row10_col1 {\n",
       "  background-color: #e0ecf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row11_col1 {\n",
       "  background-color: #e7f0fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row12_col1 {\n",
       "  background-color: #e7f1fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row13_col1 {\n",
       "  background-color: #e9f2fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row14_col1, #T_71357_row15_col1, #T_71357_row16_col1 {\n",
       "  background-color: #f5f9fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row17_col1 {\n",
       "  background-color: #f5fafe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_71357_row18_col1, #T_71357_row19_col1 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_71357\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_71357_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_71357_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_71357_row0_col0\" class=\"data row0 col0\" >user</td>\n",
       "      <td id=\"T_71357_row0_col1\" class=\"data row0 col1\" >17474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_71357_row1_col0\" class=\"data row1 col0\" >the</td>\n",
       "      <td id=\"T_71357_row1_col1\" class=\"data row1 col1\" >10156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_71357_row2_col0\" class=\"data row2 col0\" >to</td>\n",
       "      <td id=\"T_71357_row2_col1\" class=\"data row2 col1\" >10089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_71357_row3_col0\" class=\"data row3 col0\" >you</td>\n",
       "      <td id=\"T_71357_row3_col1\" class=\"data row3 col1\" >7510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_71357_row4_col0\" class=\"data row4 col0\" >i</td>\n",
       "      <td id=\"T_71357_row4_col1\" class=\"data row4 col1\" >7288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_71357_row5_col0\" class=\"data row5 col0\" >a</td>\n",
       "      <td id=\"T_71357_row5_col1\" class=\"data row5 col1\" >6416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_71357_row6_col0\" class=\"data row6 col0\" >is</td>\n",
       "      <td id=\"T_71357_row6_col1\" class=\"data row6 col1\" >6108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_71357_row7_col0\" class=\"data row7 col0\" >and</td>\n",
       "      <td id=\"T_71357_row7_col1\" class=\"data row7 col1\" >4871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_71357_row8_col0\" class=\"data row8 col0\" >in</td>\n",
       "      <td id=\"T_71357_row8_col1\" class=\"data row8 col1\" >4638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_71357_row9_col0\" class=\"data row9 col0\" >for</td>\n",
       "      <td id=\"T_71357_row9_col1\" class=\"data row9 col1\" >4479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_71357_row10_col0\" class=\"data row10 col0\" >of</td>\n",
       "      <td id=\"T_71357_row10_col1\" class=\"data row10 col1\" >4193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_71357_row11_col0\" class=\"data row11 col0\" >not</td>\n",
       "      <td id=\"T_71357_row11_col1\" class=\"data row11 col1\" >3726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_71357_row12_col0\" class=\"data row12 col0\" >my</td>\n",
       "      <td id=\"T_71357_row12_col1\" class=\"data row12 col1\" >3676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_71357_row13_col0\" class=\"data row13 col0\" >it</td>\n",
       "      <td id=\"T_71357_row13_col1\" class=\"data row13 col1\" >3549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_71357_row14_col0\" class=\"data row14 col0\" >are</td>\n",
       "      <td id=\"T_71357_row14_col1\" class=\"data row14 col1\" >2669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_71357_row15_col0\" class=\"data row15 col0\" >love</td>\n",
       "      <td id=\"T_71357_row15_col1\" class=\"data row15 col1\" >2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_71357_row16_col0\" class=\"data row16 col0\" >this</td>\n",
       "      <td id=\"T_71357_row16_col1\" class=\"data row16 col1\" >2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_71357_row17_col0\" class=\"data row17 col0\" >on</td>\n",
       "      <td id=\"T_71357_row17_col1\" class=\"data row17 col1\" >2629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_71357_row18_col0\" class=\"data row18 col0\" >with</td>\n",
       "      <td id=\"T_71357_row18_col1\" class=\"data row18 col1\" >2510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_71357_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_71357_row19_col0\" class=\"data row19 col0\" >be</td>\n",
       "      <td id=\"T_71357_row19_col1\" class=\"data row19 col1\" >2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18751e65550>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "top = Counter([word for word_list in train_df['word_list'] for word in word_list])\n",
    "temp_df = pd.DataFrame(top.most_common(20), columns=['word', 'count'])\n",
    "temp_df.style.background_gradient(cmap='Blues', axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words removal\n",
    "\n",
    "As you can see, many of the most commonly used words are not useful for identifying tweet sentiment. They belong to the stop words list and should be removed from the tweets words list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\SES100\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(word_list):\n",
    "    return [word for word in word_list if word not in stopwords.words('english')]\n",
    "\n",
    "train_df['word_list_without_sw'] = train_df['word_list'].apply(lambda x: remove_stopword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_list_without_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "      <td>user when a father is dysfunctional and is so ...</td>\n",
       "      <td>[user, when, a, father, is, dysfunctional, and...</td>\n",
       "      <td>[user, father, dysfunctional, selfish, drags, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks for lyft credit i cannot use ...</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, i, can...</td>\n",
       "      <td>[user, user, thanks, lyft, credit, use, offer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>[model, i, love, you, take, with, you, all, th...</td>\n",
       "      <td>[model, love, take, time, areð±, ððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment  \\\n",
       "0   @user when a father is dysfunctional and is s...          0   \n",
       "1  @user @user thanks for #lyft credit i can't us...          0   \n",
       "2                                bihday your majesty          0   \n",
       "3  #model   i love u take with u all the time in ...          0   \n",
       "4             factsguide: society now    #motivation          0   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  user when a father is dysfunctional and is so ...   \n",
       "1  user user thanks for lyft credit i cannot use ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                           word_list  \\\n",
       "0  [user, when, a, father, is, dysfunctional, and...   \n",
       "1  [user, user, thanks, for, lyft, credit, i, can...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, i, love, you, take, with, you, all, th...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                word_list_without_sw  \n",
       "0  [user, father, dysfunctional, selfish, drags, ...  \n",
       "1  [user, user, thanks, lyft, credit, use, offer,...  \n",
       "2                                  [bihday, majesty]  \n",
       "3  [model, love, take, time, areð±, ððð...  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's to check the most common words in the tweets after removing all stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5d3da_row0_col1 {\n",
       "  background-color: #3f007d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5d3da_row1_col1 {\n",
       "  background-color: #f0eef6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d3da_row2_col1 {\n",
       "  background-color: #f3f1f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d3da_row3_col1 {\n",
       "  background-color: #f6f5f9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d3da_row4_col1 {\n",
       "  background-color: #f7f5fa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d3da_row5_col1 {\n",
       "  background-color: #faf8fb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d3da_row6_col1, #T_5d3da_row7_col1, #T_5d3da_row8_col1, #T_5d3da_row9_col1, #T_5d3da_row10_col1 {\n",
       "  background-color: #faf9fc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d3da_row11_col1, #T_5d3da_row12_col1, #T_5d3da_row13_col1, #T_5d3da_row14_col1, #T_5d3da_row15_col1 {\n",
       "  background-color: #fbfafc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5d3da_row16_col1, #T_5d3da_row17_col1, #T_5d3da_row18_col1, #T_5d3da_row19_col1 {\n",
       "  background-color: #fcfbfd;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5d3da\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5d3da_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_5d3da_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5d3da_row0_col0\" class=\"data row0 col0\" >user</td>\n",
       "      <td id=\"T_5d3da_row0_col1\" class=\"data row0 col1\" >17474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5d3da_row1_col0\" class=\"data row1 col0\" >love</td>\n",
       "      <td id=\"T_5d3da_row1_col1\" class=\"data row1 col1\" >2668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5d3da_row2_col0\" class=\"data row2 col0\" >day</td>\n",
       "      <td id=\"T_5d3da_row2_col1\" class=\"data row2 col1\" >2198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5d3da_row3_col0\" class=\"data row3 col0\" >happy</td>\n",
       "      <td id=\"T_5d3da_row3_col1\" class=\"data row3 col1\" >1663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5d3da_row4_col0\" class=\"data row4 col0\" >amp</td>\n",
       "      <td id=\"T_5d3da_row4_col1\" class=\"data row4 col1\" >1582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5d3da_row5_col0\" class=\"data row5 col0\" >time</td>\n",
       "      <td id=\"T_5d3da_row5_col1\" class=\"data row5 col1\" >1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5d3da_row6_col0\" class=\"data row6 col0\" >life</td>\n",
       "      <td id=\"T_5d3da_row6_col1\" class=\"data row6 col1\" >1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5d3da_row7_col0\" class=\"data row7 col0\" >like</td>\n",
       "      <td id=\"T_5d3da_row7_col1\" class=\"data row7 col1\" >1042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5d3da_row8_col0\" class=\"data row8 col0\" >â¦</td>\n",
       "      <td id=\"T_5d3da_row8_col1\" class=\"data row8 col1\" >1004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5d3da_row9_col0\" class=\"data row9 col0\" >today</td>\n",
       "      <td id=\"T_5d3da_row9_col1\" class=\"data row9 col1\" >991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5d3da_row10_col0\" class=\"data row10 col0\" >new</td>\n",
       "      <td id=\"T_5d3da_row10_col1\" class=\"data row10 col1\" >983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_5d3da_row11_col0\" class=\"data row11 col0\" >people</td>\n",
       "      <td id=\"T_5d3da_row11_col1\" class=\"data row11 col1\" >950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_5d3da_row12_col0\" class=\"data row12 col0\" >positive</td>\n",
       "      <td id=\"T_5d3da_row12_col1\" class=\"data row12 col1\" >928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_5d3da_row13_col0\" class=\"data row13 col0\" >thankful</td>\n",
       "      <td id=\"T_5d3da_row13_col1\" class=\"data row13 col1\" >919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_5d3da_row14_col0\" class=\"data row14 col0\" >get</td>\n",
       "      <td id=\"T_5d3da_row14_col1\" class=\"data row14 col1\" >917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_5d3da_row15_col0\" class=\"data row15 col0\" >good</td>\n",
       "      <td id=\"T_5d3da_row15_col1\" class=\"data row15 col1\" >840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_5d3da_row16_col0\" class=\"data row16 col0\" >bihday</td>\n",
       "      <td id=\"T_5d3da_row16_col1\" class=\"data row16 col1\" >825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_5d3da_row17_col0\" class=\"data row17 col0\" >one</td>\n",
       "      <td id=\"T_5d3da_row17_col1\" class=\"data row17 col1\" >781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_5d3da_row18_col0\" class=\"data row18 col0\" >see</td>\n",
       "      <td id=\"T_5d3da_row18_col1\" class=\"data row18 col1\" >756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5d3da_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_5d3da_row19_col0\" class=\"data row19 col0\" >fathers</td>\n",
       "      <td id=\"T_5d3da_row19_col1\" class=\"data row19 col1\" >706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1877f74cc10>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = Counter([word for word_list in train_df['word_list_without_sw'] for word in word_list])\n",
    "temp_df = pd.DataFrame(top.most_common(20), columns=['word', 'count'])\n",
    "temp_df.style.background_gradient(cmap='Purples', axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most common words sentiments wise\n",
    "\n",
    "As a result of this process, we can see some meaningful words among the most common words. As we have more positive tweets in our dataset, positive words have a larger proportion. We can check the most common word in both negative and positive tweets separately. In the following cell, we will create two separate dataframes for each sentiment and repeat the above process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create seperate dataframes for each sentiment\n",
    "Positive_sent = train_df[train_df['sentiment'] == 0]\n",
    "Negative_sent = train_df[train_df['sentiment'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b191e_row0_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b191e_row1_col1 {\n",
       "  background-color: #e4f5df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row2_col1 {\n",
       "  background-color: #e9f7e5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row3_col1 {\n",
       "  background-color: #eef8ea;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row4_col1 {\n",
       "  background-color: #f1faee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row5_col1, #T_b191e_row6_col1 {\n",
       "  background-color: #f4fbf1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row7_col1 {\n",
       "  background-color: #f5fbf2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row8_col1, #T_b191e_row9_col1, #T_b191e_row10_col1, #T_b191e_row11_col1, #T_b191e_row12_col1 {\n",
       "  background-color: #f5fbf3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row13_col1, #T_b191e_row14_col1, #T_b191e_row15_col1, #T_b191e_row16_col1 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b191e_row17_col1, #T_b191e_row18_col1, #T_b191e_row19_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b191e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b191e_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_b191e_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b191e_row0_col0\" class=\"data row0 col0\" >user</td>\n",
       "      <td id=\"T_b191e_row0_col1\" class=\"data row0 col1\" >15614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_b191e_row1_col0\" class=\"data row1 col0\" >love</td>\n",
       "      <td id=\"T_b191e_row1_col1\" class=\"data row1 col1\" >2643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_b191e_row2_col0\" class=\"data row2 col0\" >day</td>\n",
       "      <td id=\"T_b191e_row2_col1\" class=\"data row2 col1\" >2190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_b191e_row3_col0\" class=\"data row3 col0\" >happy</td>\n",
       "      <td id=\"T_b191e_row3_col1\" class=\"data row3 col1\" >1651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_b191e_row4_col0\" class=\"data row4 col0\" >amp</td>\n",
       "      <td id=\"T_b191e_row4_col1\" class=\"data row4 col1\" >1314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_b191e_row5_col0\" class=\"data row5 col0\" >time</td>\n",
       "      <td id=\"T_b191e_row5_col1\" class=\"data row5 col1\" >1088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_b191e_row6_col0\" class=\"data row6 col0\" >life</td>\n",
       "      <td id=\"T_b191e_row6_col1\" class=\"data row6 col1\" >1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_b191e_row7_col0\" class=\"data row7 col0\" >today</td>\n",
       "      <td id=\"T_b191e_row7_col1\" class=\"data row7 col1\" >979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_b191e_row8_col0\" class=\"data row8 col0\" >positive</td>\n",
       "      <td id=\"T_b191e_row8_col1\" class=\"data row8 col1\" >925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_b191e_row9_col0\" class=\"data row9 col0\" >thankful</td>\n",
       "      <td id=\"T_b191e_row9_col1\" class=\"data row9 col1\" >919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_b191e_row10_col0\" class=\"data row10 col0\" >new</td>\n",
       "      <td id=\"T_b191e_row10_col1\" class=\"data row10 col1\" >914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_b191e_row11_col0\" class=\"data row11 col0\" >like</td>\n",
       "      <td id=\"T_b191e_row11_col1\" class=\"data row11 col1\" >905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_b191e_row12_col0\" class=\"data row12 col0\" >get</td>\n",
       "      <td id=\"T_b191e_row12_col1\" class=\"data row12 col1\" >883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_b191e_row13_col0\" class=\"data row13 col0\" >people</td>\n",
       "      <td id=\"T_b191e_row13_col1\" class=\"data row13 col1\" >851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_b191e_row14_col0\" class=\"data row14 col0\" >bihday</td>\n",
       "      <td id=\"T_b191e_row14_col1\" class=\"data row14 col1\" >825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_b191e_row15_col0\" class=\"data row15 col0\" >â¦</td>\n",
       "      <td id=\"T_b191e_row15_col1\" class=\"data row15 col1\" >823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_b191e_row16_col0\" class=\"data row16 col0\" >good</td>\n",
       "      <td id=\"T_b191e_row16_col1\" class=\"data row16 col1\" >807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_b191e_row17_col0\" class=\"data row17 col0\" >one</td>\n",
       "      <td id=\"T_b191e_row17_col1\" class=\"data row17 col1\" >733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_b191e_row18_col0\" class=\"data row18 col0\" >see</td>\n",
       "      <td id=\"T_b191e_row18_col1\" class=\"data row18 col1\" >731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_b191e_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_b191e_row19_col0\" class=\"data row19 col0\" >fathers</td>\n",
       "      <td id=\"T_b191e_row19_col1\" class=\"data row19 col1\" >704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x187014f97f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MosT common positive words\n",
    "top = Counter([word for word_list in Positive_sent['word_list_without_sw'] for word in word_list])\n",
    "temp_df = pd.DataFrame(top.most_common(20), columns=['word', 'count'])\n",
    "temp_df.style.background_gradient(cmap='Greens', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2dfe7_row0_col1 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2dfe7_row1_col1 {\n",
       "  background-color: #fee3d6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row2_col1 {\n",
       "  background-color: #fee9df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row3_col1 {\n",
       "  background-color: #feeae1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row4_col1 {\n",
       "  background-color: #ffeee6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row5_col1, #T_2dfe7_row6_col1 {\n",
       "  background-color: #ffeee7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row7_col1 {\n",
       "  background-color: #ffefe8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row8_col1 {\n",
       "  background-color: #fff2eb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row9_col1, #T_2dfe7_row10_col1 {\n",
       "  background-color: #fff2ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row11_col1 {\n",
       "  background-color: #fff3ed;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row12_col1 {\n",
       "  background-color: #fff4ee;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row13_col1, #T_2dfe7_row14_col1 {\n",
       "  background-color: #fff4ef;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2dfe7_row15_col1, #T_2dfe7_row16_col1, #T_2dfe7_row17_col1, #T_2dfe7_row18_col1, #T_2dfe7_row19_col1 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2dfe7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2dfe7_level0_col0\" class=\"col_heading level0 col0\" >word</th>\n",
       "      <th id=\"T_2dfe7_level0_col1\" class=\"col_heading level0 col1\" >count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2dfe7_row0_col0\" class=\"data row0 col0\" >user</td>\n",
       "      <td id=\"T_2dfe7_row0_col1\" class=\"data row0 col1\" >1860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2dfe7_row1_col0\" class=\"data row1 col0\" >amp</td>\n",
       "      <td id=\"T_2dfe7_row1_col1\" class=\"data row1 col1\" >268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2dfe7_row2_col0\" class=\"data row2 col0\" >trump</td>\n",
       "      <td id=\"T_2dfe7_row2_col1\" class=\"data row2 col1\" >197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2dfe7_row3_col0\" class=\"data row3 col0\" >â¦</td>\n",
       "      <td id=\"T_2dfe7_row3_col1\" class=\"data row3 col1\" >181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2dfe7_row4_col0\" class=\"data row4 col0\" >libtard</td>\n",
       "      <td id=\"T_2dfe7_row4_col1\" class=\"data row4 col1\" >149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_2dfe7_row5_col0\" class=\"data row5 col0\" >like</td>\n",
       "      <td id=\"T_2dfe7_row5_col1\" class=\"data row5 col1\" >137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_2dfe7_row6_col0\" class=\"data row6 col0\" >white</td>\n",
       "      <td id=\"T_2dfe7_row6_col1\" class=\"data row6 col1\" >137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_2dfe7_row7_col0\" class=\"data row7 col0\" >black</td>\n",
       "      <td id=\"T_2dfe7_row7_col1\" class=\"data row7 col1\" >131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_2dfe7_row8_col0\" class=\"data row8 col0\" >racist</td>\n",
       "      <td id=\"T_2dfe7_row8_col1\" class=\"data row8 col1\" >102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_2dfe7_row9_col0\" class=\"data row9 col0\" >people</td>\n",
       "      <td id=\"T_2dfe7_row9_col1\" class=\"data row9 col1\" >99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_2dfe7_row10_col0\" class=\"data row10 col0\" >politics</td>\n",
       "      <td id=\"T_2dfe7_row10_col1\" class=\"data row10 col1\" >96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_2dfe7_row11_col0\" class=\"data row11 col0\" >allahsoil</td>\n",
       "      <td id=\"T_2dfe7_row11_col1\" class=\"data row11 col1\" >92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_2dfe7_row12_col0\" class=\"data row12 col0\" >liberal</td>\n",
       "      <td id=\"T_2dfe7_row12_col1\" class=\"data row12 col1\" >82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_2dfe7_row13_col0\" class=\"data row13 col0\" >might</td>\n",
       "      <td id=\"T_2dfe7_row13_col1\" class=\"data row13 col1\" >77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_2dfe7_row14_col0\" class=\"data row14 col0\" >sjw</td>\n",
       "      <td id=\"T_2dfe7_row14_col1\" class=\"data row14 col1\" >74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_2dfe7_row15_col0\" class=\"data row15 col0\" >women</td>\n",
       "      <td id=\"T_2dfe7_row15_col1\" class=\"data row15 col1\" >72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_2dfe7_row16_col0\" class=\"data row16 col0\" >new</td>\n",
       "      <td id=\"T_2dfe7_row16_col1\" class=\"data row16 col1\" >69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_2dfe7_row17_col0\" class=\"data row17 col0\" >obama</td>\n",
       "      <td id=\"T_2dfe7_row17_col1\" class=\"data row17 col1\" >68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_2dfe7_row18_col0\" class=\"data row18 col0\" >us</td>\n",
       "      <td id=\"T_2dfe7_row18_col1\" class=\"data row18 col1\" >66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2dfe7_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_2dfe7_row19_col0\" class=\"data row19 col0\" >hate</td>\n",
       "      <td id=\"T_2dfe7_row19_col1\" class=\"data row19 col1\" >65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x18751e657c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MosT common negative words\n",
    "top = Counter([word for word_list in Negative_sent['word_list_without_sw'] for word in word_list])\n",
    "temp_df = pd.DataFrame(top.most_common(20), columns=['word', 'count'])\n",
    "temp_df.style.background_gradient(cmap='Reds', axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "Both stemming and lemmatization converts word to its base form. Stemming is a fast rule based technique and sometimes chops off inaccurately (under-stemming and over-stemming). You may have noticed NLTK provides PorterStemmer and a slightly improved Snowball Stemmer.\n",
    "\n",
    "Lemmatization is dictionary based technique, more accurate but slightly slower than stemming. We will use WordnetLemmatizer from NLTK. We will download the wordnet resource for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\SES100\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_list_without_sw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "      <td>user when a father is dysfunctional and is so ...</td>\n",
       "      <td>[user, when, a, father, is, dysfunctional, and...</td>\n",
       "      <td>[user, father, dysfunctional, selfish, drag, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks for lyft credit i cannot use ...</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, i, can...</td>\n",
       "      <td>[user, user, thanks, lyft, credit, use, offer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>[model, i, love, you, take, with, you, all, th...</td>\n",
       "      <td>[model, love, take, time, areð±, ððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment  \\\n",
       "0   @user when a father is dysfunctional and is s...          0   \n",
       "1  @user @user thanks for #lyft credit i can't us...          0   \n",
       "2                                bihday your majesty          0   \n",
       "3  #model   i love u take with u all the time in ...          0   \n",
       "4             factsguide: society now    #motivation          0   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  user when a father is dysfunctional and is so ...   \n",
       "1  user user thanks for lyft credit i cannot use ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                           word_list  \\\n",
       "0  [user, when, a, father, is, dysfunctional, and...   \n",
       "1  [user, user, thanks, for, lyft, credit, i, can...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, i, love, you, take, with, you, all, th...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                word_list_without_sw  \n",
       "0  [user, father, dysfunctional, selfish, drag, k...  \n",
       "1  [user, user, thanks, lyft, credit, use, offer,...  \n",
       "2                                  [bihday, majesty]  \n",
       "3  [model, love, take, time, areð±, ððð...  \n",
       "4                  [factsguide, society, motivation]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_df['word_list_without_sw'] = train_df['word_list_without_sw'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final pre-processing\n",
    "\n",
    "Let's to concatinate all the words in the last column on the dataframe and create a cleaned version of tweet text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>word_list</th>\n",
       "      <th>word_list_without_sw</th>\n",
       "      <th>final_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>0</td>\n",
       "      <td>user when a father is dysfunctional and is so ...</td>\n",
       "      <td>[user, when, a, father, is, dysfunctional, and...</td>\n",
       "      <td>[user, father, dysfunctional, selfish, drag, k...</td>\n",
       "      <td>user father dysfunctional selfish drag kid dys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks for lyft credit i cannot use ...</td>\n",
       "      <td>[user, user, thanks, for, lyft, credit, i, can...</td>\n",
       "      <td>[user, user, thanks, lyft, credit, use, offer,...</td>\n",
       "      <td>user user thanks lyft credit use offer wheelch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>[bihday, your, majesty]</td>\n",
       "      <td>[bihday, majesty]</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>0</td>\n",
       "      <td>model i love you take with you all the time in...</td>\n",
       "      <td>[model, i, love, you, take, with, you, all, th...</td>\n",
       "      <td>[model, love, take, time, areð±, ððð...</td>\n",
       "      <td>model love take time areð± ðððð ð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society now motivation</td>\n",
       "      <td>[factsguide, society, now, motivation]</td>\n",
       "      <td>[factsguide, society, motivation]</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  sentiment  \\\n",
       "0   @user when a father is dysfunctional and is s...          0   \n",
       "1  @user @user thanks for #lyft credit i can't us...          0   \n",
       "2                                bihday your majesty          0   \n",
       "3  #model   i love u take with u all the time in ...          0   \n",
       "4             factsguide: society now    #motivation          0   \n",
       "\n",
       "                                         clean_tweet  \\\n",
       "0  user when a father is dysfunctional and is so ...   \n",
       "1  user user thanks for lyft credit i cannot use ...   \n",
       "2                                bihday your majesty   \n",
       "3  model i love you take with you all the time in...   \n",
       "4                  factsguide society now motivation   \n",
       "\n",
       "                                           word_list  \\\n",
       "0  [user, when, a, father, is, dysfunctional, and...   \n",
       "1  [user, user, thanks, for, lyft, credit, i, can...   \n",
       "2                            [bihday, your, majesty]   \n",
       "3  [model, i, love, you, take, with, you, all, th...   \n",
       "4             [factsguide, society, now, motivation]   \n",
       "\n",
       "                                word_list_without_sw  \\\n",
       "0  [user, father, dysfunctional, selfish, drag, k...   \n",
       "1  [user, user, thanks, lyft, credit, use, offer,...   \n",
       "2                                  [bihday, majesty]   \n",
       "3  [model, love, take, time, areð±, ððð...   \n",
       "4                  [factsguide, society, motivation]   \n",
       "\n",
       "                                         final_tweet  \n",
       "0  user father dysfunctional selfish drag kid dys...  \n",
       "1  user user thanks lyft credit use offer wheelch...  \n",
       "2                                     bihday majesty  \n",
       "3  model love take time areð± ðððð ð...  \n",
       "4                      factsguide society motivation  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['final_tweet'] = train_df['word_list_without_sw'].apply(lambda x:' '.join(x))\n",
    "train_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Exercise</font>\n",
    "\n",
    "Next week workshop will continue the process by adding new steps to the current pipeline. However, we need to save the result of today workshop in a CSV file. Please search the internet and find the proper code to save the train dataframe as a CSV file in the current folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code goes here:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3991fcc0ba5b8a22f24240a26cc8584a86e30514acea51337cb802bdfe7c9ab5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
